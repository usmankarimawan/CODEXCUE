#importing the required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Readind Data and initial analysis
from google.colab import drive
drive.mount('/content/drive')
data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/CAR DETAILS FROM CAR DEKHO.csv')
print(data)

#data framing the dataset
df1 = pd.DataFrame(data , columns = data.drop(columns='name').columns)
df1

list(df1.columns)

#looking for NaN values
df1.isna().sum()

df1.describe()

df1['Age_n'] = df1['year'].max()+4 - df1['year']
df1.insert(1,'Age',df1.Age_n)
df1 = df1.drop(columns = 'Age_n')
df1 = df1.drop(columns = 'year')
print(df1)
df1.info()

klearn.preprocessing import LabelEncoder
label_map = {}
for col in df1.columns :
    label_encoder = LabelEncoder()
    if df1[col].dtype == 'object' :
        df1[col] = label_encoder.fit_transform(df1[col])
        label_map[col] = {'mapping': dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}
print(df1)

label_map

df1['km_driven'] = df1['km_driven'] / 1000
df1['km_driven'] = df1['km_driven'].astype(int).round(1)
print(df1)

df1.info()

plt.figure(figsize = (10,8))
sns.boxplot(data = df1 , x = 'Age' , y = 'selling_price')
plt.title('Age vs Selling Price')
plt.grid()
plt.show()

plt.figure(figsize = (10, 6))
sns.scatterplot(data = df1 , x = 'km_driven' , y = 'selling_price'  , alpha = 0.8)
plt.grid()
plt.title('Present price vs Selling Price')
plt.plot(plt.xlim(),plt.ylim(),color = 'gray' , linestyle = '--' , alpha = 0.4)

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold , cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
model = LinearRegression()

x = df1.drop(columns='selling_price')
y = df1['selling_price'].values.reshape(-1,1)

x_train , x_test, y_train , y_test = train_test_split(x,y,test_size=0.2)

scaler = StandardScaler()

x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

for k in range(2,12):
    kf = KFold(n_splits = k)
    print(f"For {k} Folds : {np.mean(cross_val_score(model,x,y,cv=kf , scoring = 'r2' ))} ")

for k in range(2,12):
    kf = KFold(n_splits = k)
    print(f"For {k} Folds : {np.mean(cross_val_score(model,x_train,y_train,cv=kf , scoring = 'r2' ))} ")

for k in range(2,12):
    kf = KFold(n_splits = k)
    print(f"For {k} Folds : {np.mean(cross_val_score(model,x_test,y_test,cv=kf , scoring = 'r2' ))} ")

kf = KFold(n_splits=10)
cvs = cross_val_score(model,x,y,cv=kf , scoring = 'r2' )
cvs

model.fit(x_train , y_train)
print('Training Accuracy : ' , model.score(x_train , y_train))
print('Testing Accuracy : ' , model.score(x_test , y_test))

y_pred = model.predict(x_test)

print('Mean Absolute Error : ',mean_absolute_error(y_test,y_pred))
print('Mean Squared Error : ',mean_squared_error(y_test,y_pred))
print('Root Mean Squared Error : ' , np.sqrt(mean_squared_error(y_test,y_pred)))
print('R2 Score : ',r2_score(y_test,y_pred))

from sklearn.preprocessing import PolynomialFeatures
from sklearn.feature_selection import RFE

poly_features = PolynomialFeatures(degree = 2 , include_bias=False)
x_poly = poly_features.fit_transform(x)

x_train_poly , x_test_poly , y_train , y_test = train_test_split(x_poly,y,test_size=0.2)

x_train_poly = scaler.fit_transform(x_train_poly)
x_test_poly = scaler.transform(x_test_poly)

model.fit(x_train_poly , y_train)
print('Training Accuracy : ' , model.score(x_train_poly , y_train))
print('Testing Accuracy : ' , model.score(x_test_poly , y_test))

y_pred = model.predict(x_test_poly)

print('Mean Absolute Error : ',mean_absolute_error(y_test,y_pred))
print('Mean Squared Error : ',mean_squared_error(y_test,y_pred))
print('Root Mean Squared Error : ' , np.sqrt(mean_squared_error(y_test,y_pred)))
print('R2 Score : ',r2_score(y_test,y_pred))

plt.figure(figsize = (10,6))
plt.scatter(y_test,y_pred,alpha = 0.5)
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.grid()
plt.title('Actual vs Predicted Values')
plt.plot(plt.xlim(),plt.ylim(), '--',linewidth=.5,color='gray' )
plt.show()

poly_feature_names = poly_features.get_feature_names_out()
poly_feature_names

x_poly_df = pd.DataFrame(x_poly , columns = poly_feature_names)

x_train_poly , x_test_poly , y_train , y_test = train_test_split(x_poly_df , y , test_size=0.2)

x_train_poly = scaler.fit_transform(x_train_poly)
x_test_poly = scaler.transform(x_test_poly)

rfe = RFE(model , n_features_to_select=None)
rfe.fit(x_train_poly , y_train)

primary_features = np.array(poly_feature_names)[rfe.support_]
primary_features

primary_features.shape

x_poly_primary = x_poly_df[primary_features]
x_poly_primary

x_train_poly_primary , x_test_poly_primary , y_train , y_test = train_test_split(x_poly_primary , y , test_size=0.2)


x_train_pp = scaler.fit_transform(x_train_poly_primary)
x_test_pp = scaler.transform(x_test_poly_primary)

model.fit(x_train_pp , y_train)
print('Training Accuracy : ' , model.score(x_train_pp , y_train))
print('Testing Accuracy : ' , model.score(x_test_pp , y_test))

y_pred = model.predict(x_test_pp)

print('Mean Absolute Error : ',mean_absolute_error(y_test,y_pred))
print('Mean Squared Error : ',mean_squared_error(y_test,y_pred))
print('Root Mean Squared Error : ' , np.sqrt(mean_squared_error(y_test,y_pred)))
print('R2 Score : ',r2_score(y_test,y_pred))

plt.figure(figsize = (10,6))
plt.scatter(y_test,y_pred,alpha = 0.5)
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.grid()
plt.title('Actual vs Predicted Values')
plt.plot(plt.xlim(),plt.ylim(), '--',linewidth=.5,color='gray' )
plt.show()

