import numpy as np
import pandas as pd

url= "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv"
dfr = pd.read_csv(url, header=0)
print(dfr.info())
print(dfr.describe())
dfr.shape

#REMOVE MISSING VALUES (if method shows missing values)
dfr.isnull().sum()
dfr.dropna(inplace=True)

# DUPLICATES CHECK
duplicate_rows = dfr.duplicated()
print("Number of duplicate rows:", duplicate_rows.sum())
dfr.drop_duplicates(inplace=True)

# CHECK CLASS DISTRIBUTION
print(dfr['smoker'].value_counts())
print(dfr['sex'].value_counts())
print(dfr['day'].value_counts())
print(dfr['time'].value_counts())

# HOT-ENCODING DATA
dfr['sex'] = dfr['sex'].map({'Male':1,'Female':0})
dfr['smoker'] = dfr['smoker'].map({'No':1,'Yes':0})
dfr['day'] = dfr['day'].map({'Sat':1,'Sun':2,'Thur':3,'Fri':4})
dfr['time'] = dfr['time'].map({'Dinner':1,'Lunch':0})

# REMOVE OUTLIERS using IQR method
import matplotlib.pyplot as plt
def plot_boxplot(dfr, ft):
  dfr.boxplot(column=[ft])
  plt.grid(False)
  plt.show()

plot_boxplot(dfr,"tip")
plt.show()
plot_boxplot(dfr,"total_bill")
plt.show()
plot_boxplot(dfr,"size")
plt.show()

def outliers(dfr, ft):
  Q1 = dfr[ft].quantile(0.25)
  Q3 = dfr[ft].quantile(0.75)
  IQR = Q3 - Q1
  LL = Q1 - 1.5*IQR
  UL = Q3 + 1.5*IQR

  Is = dfr.index[(dfr[ft]<LL) | (dfr[ft]>UL)]
  return Is

index_list = []
for feature in [ 'tip','total_bill','size']:
  index_list.extend(outliers(dfr,feature))

print(index_list)

def remove(dfr,Is):
  Is = sorted(set(Is))
  dfr = dfr.drop(Is)
  return dfr

dfc = remove(dfr, index_list)
print(dfc.shape)

plot_boxplot(dfc, 'tip')
plt.show()

#DEFINE TRAINING FEATURES
X= dfc.drop(columns=['tip'])
print(X)

#DEFINE LABEL
y= dfc['tip']
print(y)

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold , cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
model = LinearRegression()

#SPLIT DATA SET INTO TRAIN-TEST FEATURES
x_train , x_test, y_train , y_test = train_test_split(x,y,test_size=0.2)
scaler = StandardScaler()

x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

for k in range(2,12):
    kf = KFold(n_splits = k)
    print(f"For {k} Folds : {np.mean(cross_val_score(model,x,y,cv=kf , scoring = 'r2' ))} ")

for k in range(2,12):
    kf = KFold(n_splits = k)
    print(f"For {k} Folds : {np.mean(cross_val_score(model,x_train,y_train,cv=kf , scoring = 'r2' ))} ")

for k in range(2,12):
    kf = KFold(n_splits = k)
    print(f"For {k} Folds : {np.mean(cross_val_score(model,x_test,y_test,cv=kf , scoring = 'r2' ))} ")

kf = KFold(n_splits=10)
cvs = cross_val_score(model,x,y,cv=kf , scoring = 'r2' )
cvs

model.fit(x_train , y_train)
print('Training Accuracy : ' , model.score(x_train , y_train))
print('Testing Accuracy : ' , model.score(x_test , y_test))

y_pred = model.predict(x_test)

print('Mean Absolute Error : ',mean_absolute_error(y_test,y_pred))
print('Mean Squared Error : ',mean_squared_error(y_test,y_pred))
print('Root Mean Squared Error : ' , np.sqrt(mean_squared_error(y_test,y_pred)))
print('R2 Score : ',r2_score(y_test,y_pred))

from sklearn.preprocessing import PolynomialFeatures

poly_features = PolynomialFeatures(degree = 2 , include_bias=False)
x_poly = poly_features.fit_transform(x)

x_train_poly , x_test_poly , y_train , y_test = train_test_split(x_poly,y,test_size=0.2)

x_train_poly = scaler.fit_transform(x_train_poly)
x_test_poly = scaler.transform(x_test_poly)

model.fit(x_train_poly , y_train)
print('Training Accuracy : ' , model.score(x_train_poly , y_train))
print('Testing Accuracy : ' , model.score(x_test_poly , y_test))

y_pred = model.predict(x_test_poly)

print('Mean Absolute Error : ',mean_absolute_error(y_test,y_pred))
print('Mean Squared Error : ',mean_squared_error(y_test,y_pred))
print('Root Mean Squared Error : ' , np.sqrt(mean_squared_error(y_test,y_pred)))
print('R2 Score : ',r2_score(y_test,y_pred))

#CHECK PREDICTION ACCURACY
import matplotlib.pyplot as plt
plt.scatter(y_test, y_pred, c= 'green')
plt.xlabel("Actual tip")
plt.ylabel("Predicted tip")
plt.grid()
plt.title('Actual tip vs Predicted tip')
plt.plot(plt.xlim(),plt.ylim(), '--',linewidth=.5,color='gray' )
plt.show()

